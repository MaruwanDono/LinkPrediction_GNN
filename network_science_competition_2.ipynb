{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3foQrt0lRjU"
      },
      "source": [
        "#NS competion 2: link predicition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AWIU1cSlQRl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import random\n",
        "import gdown\n",
        "import io\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2c9CVz46NQGP"
      },
      "outputs": [],
      "source": [
        "!pip install -U dgl==0.8.1 dglgo -f https://data.dgl.ai/wheels/repo.html -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M62fLxAzNTnq"
      },
      "outputs": [],
      "source": [
        "import dgl\n",
        "from dgl import function as fn\n",
        "#from dgl.nn import SAGEConv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0erg6nnrSMC"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYIsTKa66tBu"
      },
      "source": [
        "# Import data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RA9LwCXuldah",
        "outputId": "d8d426e8-26f6-4e79-9d3b-768e978f0c92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.249337, -0.303307, -0.057047, -0.077672, -0.012694, 0.553903, -0.173514, -0.310603, -0.193071, -0.624521, -0.239897, -0.182226, 0.328767, -0.232109, 0.08823, -0.368747, 0.072896, -0.17389, 0.080462, 0.221433, -0.003497, 0.798653, 0.389034, 0.309438, -0.612104, 0.412809, 0.040785, -0.375882, -0.30351, 0.103221, -0.038266, 0.259194)\n"
          ]
        }
      ],
      "source": [
        "#node_feat.txt\n",
        "url = 'https://drive.google.com/uc?id=1j5lJ7ySt8gYKgPrEiDqk4p0IvQvh60My'\n",
        "output = io.BytesIO()\n",
        "gdown.download(url, output, quiet=True)\n",
        "output.seek(0)\n",
        "content = output.read().decode('utf-8')\n",
        "feats = []\n",
        "for line in content.split('\\n')[:-1]:\n",
        "    feat = tuple(float(x) for x in line.split(' '))\n",
        "    feats.append(feat)\n",
        "print(feats[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jdaaqiz8Ryh",
        "outputId": "ddd16fa2-7131-43f1-f7c2-8879d55b604c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12586, 10728)\n"
          ]
        }
      ],
      "source": [
        "#train_edges.txt\n",
        "url = 'https://drive.google.com/uc?id=1NKNa9SbO_ishoJWGX2nvx3xf4rEzwhvN'\n",
        "output = io.BytesIO()\n",
        "gdown.download(url, output, quiet=True)\n",
        "output.seek(0)\n",
        "content = output.read().decode('utf-8')\n",
        "edges = []\n",
        "for line in content.split('\\n')[:-1]:\n",
        "    edge = tuple(int(x) for x in line.split(' '))\n",
        "    edges.append(edge)\n",
        "print(edges[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zvj9UfkD8Sg5",
        "outputId": "37322f3a-93fc-4896-fd4f-8a9194feefea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1262, 2232)\n"
          ]
        }
      ],
      "source": [
        "#unlabeled_nodes.txt\n",
        "url = 'https://drive.google.com/uc?id=1QQa_mgW3qFCQ8ZHKDtDsSfjuhKcP5AOR'\n",
        "output = io.BytesIO()\n",
        "gdown.download(url, output, quiet=True)\n",
        "output.seek(0)\n",
        "content = output.read().decode('utf-8')\n",
        "unlabeled_nodes = []\n",
        "for line in content.split('\\n')[:-1]:\n",
        "    edg = tuple(int(x) for x in line.split(' '))\n",
        "    unlabeled_nodes.append(edg)\n",
        "print(unlabeled_nodes[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDVtBZDQg_Jd",
        "outputId": "b58e2c88-7679-47a4-f053-c5932bbe6406"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12588\n",
            "14322\n",
            "44014\n"
          ]
        }
      ],
      "source": [
        "N = len(feats)\n",
        "print(N)\n",
        "print(len(edges))\n",
        "print(len(unlabeled_nodes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLlItg1vjEJK"
      },
      "source": [
        "Build the directed graph:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvGjg0bhjHTo",
        "outputId": "ff9bcd0f-72a5-4906-8211-73a916b0cbdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DiGraph with 12588 nodes and 14322 edges\n"
          ]
        }
      ],
      "source": [
        "G = nx.DiGraph()\n",
        "for i, feat in enumerate(feats):\n",
        "    G.add_node(i, feature=feat)\n",
        "G.add_edges_from(edges)\n",
        "print(G)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9u8m0WPsdY8"
      },
      "source": [
        "# GNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isxUYyLsNxlo"
      },
      "outputs": [],
      "source": [
        "class GCNMessagePassingLayer(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(in_dim, out_dim)\n",
        "    def forward(self, h, graph):\n",
        "        with graph.local_scope():\n",
        "            graph = graph.add_self_loop()\n",
        "            norm = graph.in_degrees()[:, None] ** (-0.5)\n",
        "            graph.ndata['h'] = self.dense(h) * norm\n",
        "\n",
        "            graph.update_all(fn.copy_src(src='h', out='m'),\n",
        "                             fn.sum(msg='m', out='h'))\n",
        "        return graph.ndata['h'] * norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUSyokcFsqL2"
      },
      "outputs": [],
      "source": [
        "class GCNEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(GCNEncoder, self).__init__()\n",
        "        self.conv1 = GCNMessagePassingLayer(input_dim, hidden_dim)\n",
        "        self.conv2 = GCNMessagePassingLayer(hidden_dim, output_dim)\n",
        "        #self.Dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        h = self.conv1(x, adj)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(h, adj)\n",
        "        return h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nIpufXNsjPD"
      },
      "outputs": [],
      "source": [
        "class MLPDecoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super(MLPDecoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
        "        #self.Dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        #Hadamard product\n",
        "        x = torch.mul(x1, x2)\n",
        "        #x = (x1 - x2) ** 2\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return torch.sigmoid(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "En-6bv-Ms0q2"
      },
      "source": [
        "Negative sampling:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CX1WWg_-s2lC"
      },
      "outputs": [],
      "source": [
        "def negative_sampling(edges, n_nodes, n_neg_samples):\n",
        "    neg_samples = []\n",
        "    while len(neg_samples) < n_neg_samples:\n",
        "        i = random.randint(0,n_nodes-1)\n",
        "        j = random.randint(0,n_nodes-1)\n",
        "        if (i,j) not in set(edges+neg_samples+unlabeled_nodes):\n",
        "            neg_samples.append((i,j))\n",
        "    return neg_samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_BREUDFva9H"
      },
      "source": [
        "Construct adjacency matrix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sIZ8Jdjvfq8"
      },
      "outputs": [],
      "source": [
        "\n",
        "#graph = dgl.from_networkx(G)\n",
        "neg_edges = negative_sampling(edges, len(G), int(1*len(edges)))\n",
        "\n",
        "pos_samples = torch.tensor(edges, dtype=torch.long)\n",
        "pos_labels = torch.ones(len(edges), dtype=torch.float)\n",
        "\n",
        "neg_samples = torch.tensor(neg_edges, dtype=torch.long)\n",
        "neg_labels = torch.zeros(len(neg_samples), dtype=torch.float)\n",
        "\n",
        "train_samples = torch.cat([pos_samples, neg_samples], dim=0)\n",
        "train_labels = torch.cat([pos_labels, neg_labels], dim=0)\n",
        "\n",
        "\n",
        "adj = nx.adjacency_matrix(G).todense()\n",
        "adj = torch.tensor(adj, dtype=torch.float)\n",
        "features = torch.tensor(feats, dtype=torch.float)\n",
        "\n",
        "s_train, s_test, l_train, l_test = train_test_split(train_samples, train_labels, test_size=0.2, random_state=42)\n",
        "#train_samples = s_train\n",
        "#train_labels = l_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIjitmyNwFGj"
      },
      "outputs": [],
      "source": [
        "#train_samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHiwLaUYE4XA"
      },
      "source": [
        "Training the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaovWl2htWsT"
      },
      "outputs": [],
      "source": [
        "input_dim = 32\n",
        "hidden_dim = 256\n",
        "output_dim = 128\n",
        "mlp_hidden_dim = 256\n",
        "learning_rate = 0.01\n",
        "num_epochs = 200\n",
        "\n",
        "encoder = GCNEncoder(input_dim, hidden_dim, output_dim)\n",
        "decoder = MLPDecoder(output_dim, mlp_hidden_dim)\n",
        "model = nn.Sequential(encoder, decoder)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "graph = dgl.from_networkx(G)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6xEmk8qE6W0"
      },
      "outputs": [],
      "source": [
        "def execute_model(model, train_samples, train_labels, patience=100):\n",
        "    model.train()\n",
        "    wait = 0\n",
        "    best_loss = np.inf\n",
        "    min_delta = 1\n",
        "    for epoch in range(num_epochs):\n",
        "        optimizer.zero_grad()\n",
        "        #embeddings = encoder(features, pos_samples.t())\n",
        "        embeddings = encoder(features, graph)\n",
        "        train_edge_embeddings1 = embeddings[train_samples[:, 0]]\n",
        "        train_edge_embeddings2 = embeddings[train_samples[:, 1]]\n",
        "        train_predictions = decoder(train_edge_embeddings1, train_edge_embeddings2).squeeze()\n",
        "\n",
        "        loss = criterion(train_predictions, train_labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}')\n",
        "        if loss < best_loss - min_delta:\n",
        "            best_loss = loss\n",
        "            wait = 0\n",
        "        else:\n",
        "            wait += 1\n",
        "            if wait >= patience:\n",
        "                break\n",
        "    return model\n",
        "\n",
        "    #accuracy = (predicted_labels == train_labels).sum().item() / train_labels.size(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XgEcoJ9PBi3"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, s_test, l_test):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        embeddings = encoder(features, graph)\n",
        "        #embeddings = encoder(features, pos_samples.t())\n",
        "        test_edge_embeddings1 = embeddings[s_test[:, 0]]\n",
        "        test_edge_embeddings2 = embeddings[s_test[:, 1]]\n",
        "        test_predictions = decoder(test_edge_embeddings1, test_edge_embeddings2).squeeze()\n",
        "        predicted_labels = torch.round(test_predictions).long()\n",
        "        correct_predictions = (predicted_labels == l_test).sum().item()\n",
        "        total_predictions = l_test.size(0)\n",
        "        accuracy = correct_predictions / total_predictions\n",
        "        print(f'Training Accuracy: {accuracy}')\n",
        "        print(balanced_accuracy_score(l_test, predicted_labels))\n",
        "        return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6Vuzez4dYJF"
      },
      "outputs": [],
      "source": [
        "model = execute_model(model, train_samples, train_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATU71C36FRt2"
      },
      "source": [
        "Model evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_NMCHVSj0Oj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c70c24a-bfcf-4d5a-cd5a-918682e5e0d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.973676860773635\n",
            "0.973676860773635\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.973676860773635"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ],
      "source": [
        "evaluate_model(model, train_samples, train_labels)\n",
        "#evaluate_model(s_test, l_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wr9NQXy5PlBX"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'trained_model.pth')\n",
        "load = False\n",
        "if load:\n",
        "    model.load_state_dict(torch.load('trained_model.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4SiClCoFAme"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    embeddings = encoder(features, graph)\n",
        "    #embeddings = encoder(features, pos_samples.t())\n",
        "    unlabeled_samples = torch.tensor(unlabeled_nodes, dtype=torch.long)\n",
        "    unlabeled_predictions = decoder(embeddings[unlabeled_samples[:, 0]], embeddings[unlabeled_samples[:, 1]]).squeeze()\n",
        "    unlabeled_predictions = torch.round(unlabeled_predictions).long()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmdXqWiVJCNm"
      },
      "outputs": [],
      "source": [
        "prediction = [(i, label) for i, label in enumerate(unlabeled_predictions)]\n",
        "with open('submission.csv','w') as f:\n",
        "    f.write('ID,Edge\\n')\n",
        "    for i, label in enumerate(unlabeled_predictions):\n",
        "        f.write(f'{i}, {label}\\n')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPSN/dd1mx1RvMtDeQIddXT"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}